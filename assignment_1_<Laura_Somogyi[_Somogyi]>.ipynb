{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#imported the rest just in case\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go4iC19RGSQw"
      },
      "source": [
        "# Task 1 -> Identifying the Prediction Target\n",
        "\n",
        "*   Inspect the dataset and identify which column should be treated as the target variable for this assignment.\n",
        "*   Justify why this column represents the appropriate prediction objective in the context of the marketing campaign\n",
        "\n",
        "\n",
        "*   Identify at least two other variables that could superficially appear to be valid targets and explain why they should not be treated as the prediction objective\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My answers\n",
        "\n",
        "* The column that should be treated as a target variable is the \"y\" column since it adresses the question whether the client will subscribe to the term deposit or not.\n",
        "\n",
        "*  It is appropriate prediction objective in the context of the marketing campaign because as I mentioned above the subscribed or not will be marked here and this decides whether the bank gets a share from penalties or not or they manage to get a client or not.\n",
        "\n",
        "* potential other target variables\n",
        "    * \"poutcome\" column\n",
        "        * This feature represents whether the previous campain was successful, failed or none-existent.\n",
        "        * This could be a reasonable if we had information about the previous interviews like duration and when it took place. However the reason I did not pick this is it may be correlated with the one included in this dataset. So the outcome may include the effect of both. \n",
        "    * \"balance\" column\n",
        "        * It could be a possible target because it keeps track of the average yearly balance on the term deposit account and this can be predicted from many variables.\n",
        "        * However I will not treat this as a prediction objective because it is not available at the time when we want to predict whether the client will commit to the creation of the account or not. Until then the balance is either 0 or missing or simply just unknown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pfiCCfzU6_y"
      },
      "source": [
        "# Task 2 Task Ordering\n",
        "\n",
        "*   Lecture material:\n",
        "    *   Lecture 2 (Data Splitting and Leakage), Lecture 5 (Preprocessing), Lecture 9 (ML Pipeline)\n",
        "*   Determine the correct order in which the data preparation tasks in this assignment should be performed\n",
        "*   Provide a structured justification for your chosen order\n",
        "*   For each step in your proposed sequence, explain:\n",
        "    *   what information is allowed to be used at that stage;\n",
        "    *   what information must not be used;\n",
        "    *   what type of data leakage could occur if the order were changed\n",
        "*   discuss at least one example of an incorrect ordering and explain the consequences it would have on model evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My answer\n",
        "\n",
        "For the order I have decided on the one which can be seen in thes jupyter notebook for the following reasongs:\n",
        "* \n",
        "*\n",
        "*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5wgsqetIaRz"
      },
      "source": [
        "# Task 3: Data Loading and Exploration\n",
        "Lecture material: Lecture 1 (Problem Formulation), Lecture 2 (Data Inspection and EDA).\n",
        "\n",
        "• Load the dataset into a Pandas DataFrame.\n",
        "\n",
        "• Inspect the structure of the dataset: number of observations, number of features, data types, and basic\n",
        "summary statistics.\n",
        "\n",
        "• Identify which variables are numerical and which are categorical\n",
        "\n",
        " Analyze the distribution of the target variable and comment on potential class imbalance.\n",
        "\n",
        "• Detect explicit and implicit missing values (e.g., special categories such as unknown).\n",
        "\n",
        "• Visualize the distribution of at least:\n",
        "\n",
        "    – two numerical variables; and\n",
        "    – two categorical variables.\n",
        "\n",
        "\n",
        "• Identify at least one variable that may require special consideration before modeling (e.g., due to distributional\n",
        "properties, extreme skewness, or availability at prediction time), and briefly justify your reasoning.\n",
        "\n",
        "Note: Exploratory analysis is not a checklist of plots. Each visualization or statistic should support a specific\n",
        "observation or hypothesis about the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bank_data = pd.read_csv('bank-additional-full.csv')\n",
        "bank_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkZsh9v5VBkM"
      },
      "source": [
        "# Task 4 Managing Missing Values\n",
        "\n",
        "Lecture material: Lecture 2 (Data Inspection), Lecture 5 (Preprocessing and Pipeline Discipline).\n",
        "\n",
        "• Identify both explicit missing values (e.g., NaN) and implicit missing values (e.g., categories such as unknown\n",
        "or sentinel numerical values, i.e., values that may represent special codes rather than genuine measurements).\n",
        "\n",
        "• Quantify the extent of missingness for each affected variable.\n",
        "\n",
        "• Propose and justify a strategy for handling missing values in each case (e.g., removal, imputation, separate\n",
        "category, indicator variable).\n",
        "\n",
        "• Clearly state which operations must be fitted using the training set only, and explain why.\n",
        "Note: Your strategy should distinguish between “data cleaning” decisions (e.g., correcting inconsistent entries)\n",
        "and “modeling” decisions (e.g., whether missingness itself may carry predictive information)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctw-yNjmHuEc"
      },
      "source": [
        "# Task 5: Encoding Categorical Variables\n",
        "\n",
        "Lecture material: Lecture 4 (Categorical Encoding), Lecture 6 (Linear Models), Lecture 9 (Feature Engineering\n",
        "and Expressiveness).\n",
        "\n",
        "• Identify all categorical variables in the dataset.\n",
        "\n",
        "• Distinguish between nominal variables (categories without intrinsic order, e.g., job type) and ordinal variables\n",
        "(categories with a meaningful order, e.g., education level), and justify your classification.\n",
        "\n",
        "• Select and apply an appropriate encoding strategy for each categorical variable.\n",
        "\n",
        "• Clearly state which encoders must be fitted on the training set only, and explain why.\n",
        "\n",
        "• Analyze how encoding changes:\n",
        "\n",
        "    – the dimensionality of the dataset;\n",
        "    – the interpretability of model coefficients;\n",
        "    – the types of decision boundaries a linear model can represent.\n",
        "\n",
        "Note: Encoding is not a purely mechanical transformation. Your justification should explicitly connect your encoding\n",
        "decisions to the assumptions and behavior of Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW5dQHOhGzsr"
      },
      "source": [
        "# Task 6: Feature Selection\n",
        "Lecture material: Lecture 5 (Feature Selection), Lecture 6 (Linear Models), Lecture 9 (Pipeline Discipline).\n",
        "\n",
        "• Identify and remove features with very low variance, if any. Justify the criterion used to define “low” variance.\n",
        "\n",
        "• Identify highly correlated numerical features and decide whether any should be removed. Clearly state the\n",
        "threshold used and justify your decision.\n",
        "\n",
        "• Discuss whether any features should be removed based on conceptual considerations (e.g., redundancy,\n",
        "availability at prediction time, or risk of data leakage).\n",
        "\n",
        "• Explain why feature selection must be performed using the training set only.\n",
        "\n",
        "• Discuss the consequences of performing feature selection on the entire dataset before splitting.\n",
        "Note: Feature selection is not purely statistical. Your reasoning should explicitly connect your decisions to the assumptions and stability of Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX9OJkSKILEH"
      },
      "source": [
        "# Task 7: Data Splitting\n",
        "Lecture material: Lecture 2 (Data Splitting and Leakage), Lecture 9 (ML Pipeline).\n",
        "\n",
        "• Split the dataset into training, validation, and test sets.\n",
        "\n",
        "• Justify your choice of proportions for each split.\n",
        "\n",
        "• Perform stratified splitting with respect to the target variable and explain why stratification is necessary for\n",
        "this dataset.\n",
        "\n",
        "• Clearly describe at which stage of your pipeline the split must occur, and explain what types of data leakage\n",
        "would arise if splitting were performed later.\n",
        "\n",
        "Note: A recommended strategy is to first split the dataset into a training set and a temporary set, and then\n",
        "split the temporary set into validation and test sets. Use the stratify argument of train test split where\n",
        "appropriate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8M5V8dzIyCo"
      },
      "source": [
        "# Task 8 Addressing Class Imbalance\n",
        "\n",
        "Lecture material: Lecture 3 (Class Imbalance), Lecture 4 (Evaluation Metrics), Lecture 9 (Pipeline Discipline).\n",
        "\n",
        "• Quantify the class distribution in the training set and explain why imbalance is or is not a concern for this\n",
        "prediction task.\n",
        "\n",
        "• Propose and apply a resampling strategy (e.g., random oversampling, SMOTE, or ADASYN). Clearly justify\n",
        "at which stage of the pipeline the resampling step should occur.\n",
        "\n",
        "• Justify your choice of resampling method in terms of its assumptions and expected effect on the learning\n",
        "algorithm.\n",
        "\n",
        "• Explain what would happen if resampling were applied before splitting the dataset into training, validation,\n",
        "and test sets. Discuss the implications for model evaluation.\n",
        "\n",
        "• Briefly discuss how class imbalance affects evaluation metrics such as accuracy, precision, and recall.\n",
        "\n",
        "Note: Resampling is part of the training procedure and must be applied to the training set only. Validation and\n",
        "test sets must preserve the original class distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O24lGOXTHNbF"
      },
      "source": [
        "# Task 9: Feature Scaling\n",
        "\n",
        "Lecture material: Lecture 5 (Feature Scaling), Lecture 6 (Logistic Regression and Optimization)..\n",
        "\n",
        "• Identify the numerical variables that require scaling.\n",
        "\n",
        "• Select and apply an appropriate scaling strategy (e.g., standardization or normalization) to those variables.\n",
        "\n",
        "• Justify your choice of scaling method in the context of Logistic Regression.\n",
        "\n",
        "• Clearly state which transformations must be fitted on the training set only, and explain why.\n",
        "\n",
        "• Discuss how feature scaling affects\n",
        "\n",
        "    – gradient-based optimization;\n",
        "    – the magnitude and comparability of model coefficients;\n",
        "    – the interpretation of regularization penalties.\n",
        "\n",
        "Note: Feature scaling is not a cosmetic transformation. Your justification should explicitly connect your scaling\n",
        "decision to the mathematical behavior of linear models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNi5jlpqXS52"
      },
      "source": [
        "# Task 10 training a Logistic Regression Model\n",
        "\n",
        "Lecture material: Lecture 6 (Logistic Regression), Lecture 9–11 (Model Evaluation and Metrics).\n",
        "• Train a Logistic Regression model to predict whether a client subscribes to a term deposit.\n",
        "• Use the validation set to generate predictions.\n",
        "• Report at least Accuracy, Precision, and Recall on the validation set.\n",
        "• Compare the model’s accuracy with the Zero Rule baseline and briefly interpret the result.\n",
        "Note: The goal here is not to squeeze out the best possible performance. The goal is to verify that your data\n",
        "preparation pipeline is coherent and correctly implemented. If your preprocessing is principled, the model should\n",
        "behave sensibly. If it behaves strangely, that is a signal to revisit earlier decisions. Have fun finding a visually\n",
        "appealing way to display the predictions or the confusion matrix on the validation set. This is your chance to make\n",
        "the output readable and professional 8-)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNVUlrwMdGr4Ufh3iwQe1M1",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
